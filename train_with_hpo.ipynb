{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loadset import create_dataloaders\n",
    "from src.dynamic_batching import find_optimal_batch_size\n",
    "from src.setup_training import setup_training\n",
    "from src.run_epoch_and_eval import train_one_epoch , evaluate , find_optimal_threshold\n",
    "import torch\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ax.api.client import Client\n",
    "from ax.api.configs import ChoiceParameterConfig, RangeParameterConfig\n",
    "\n",
    "from pyre_extensions import assert_is_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ca6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f05bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58811583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and experiment with the desired parameters\n",
    "parameters=[\n",
    "        RangeParameterConfig(\n",
    "            name=\"embedding_dim\",\n",
    "            bounds=(90, 500),\n",
    "            parameter_type=\"int\",\n",
    "            scaling=\"log\",  # Sample this parameter in log transformed space\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"learning_rate\",\n",
    "            bounds=(1e-5, 1e-2),\n",
    "            parameter_type=\"float\",\n",
    "            scaling=\"log\",\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"n_conv_layers\",\n",
    "            bounds=(2, 4),\n",
    "            parameter_type=\"int\",\n",
    "            scaling=\"linear\",\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"num_layers\",\n",
    "            bounds=(2, 8),\n",
    "            parameter_type=\"int\",\n",
    "            scaling=\"linear\",\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"num_heads\",\n",
    "            bounds=(2, 6),\n",
    "            parameter_type=\"int\",\n",
    "            scaling=\"linear\",\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"mlp_ratio\",\n",
    "            bounds=(1.0, 4.0),\n",
    "            parameter_type=\"float\",\n",
    "            scaling=\"linear\",\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"dropout_rate\",\n",
    "            bounds=(0.1, 0.5),\n",
    "            parameter_type=\"float\",\n",
    "            scaling=\"linear\",\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"attention_dropout\",\n",
    "            bounds=(0.0, 0.5),\n",
    "            parameter_type=\"float\",\n",
    "            scaling=\"linear\",\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_client.configure_experiment(parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_client.configure_optimization(\n",
    "    objective=\"exact_match_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_cct import MultiLabelCCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff0c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_hpo_parameters(hpo_parameters):\n",
    "    model = MultiLabelCCT(\n",
    "        img_size=(192, 668),\n",
    "        embedding_dim=hpo_parameters['embedding_dim'],\n",
    "        n_input_channels=3,\n",
    "        n_conv_layers=hpo_parameters['n_conv_layers'],\n",
    "        kernel_size=7,\n",
    "        stride=2,\n",
    "        padding=3,\n",
    "        pooling_kernel_size=3,\n",
    "        pooling_stride=2,\n",
    "        pooling_padding=1,\n",
    "        num_layers=hpo_parameters['num_layers'],\n",
    "        num_heads=hpo_parameters['num_heads'],\n",
    "        mlp_ratio=hpo_parameters['mlp_ratio'],\n",
    "        dropout_rate=hpo_parameters['dropout_rate'],\n",
    "        attention_dropout=hpo_parameters['attention_dropout'],\n",
    "        num_classes=15,\n",
    "        positional_embedding='learnable',\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d93483",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"/home/baraa/Desktop/testroch/DSED_strong_label/dataset/metadata/eval/combined_weak_labels.csv\"\n",
    "IMG_DIR = '/home/baraa/Desktop/testroch/DSED_strong_label/dataset/audio/eval/combined_mel'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0dc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_weights(train_loader):\n",
    "    all_labels = []\n",
    "    for _, labels in train_loader.dataset:\n",
    "        all_labels.append(labels)\n",
    "    all_labels = torch.stack(all_labels)\n",
    "    \n",
    "    # Calculate positive class frequencies\n",
    "    pos_counts = all_labels.sum(dim=0)\n",
    "    neg_counts = len(all_labels) - pos_counts\n",
    "    \n",
    "    # Use a more conservative weighting scheme\n",
    "    # pos_weights = torch.sqrt(neg_counts / (pos_counts + 1e-8))\n",
    "    pos_weights = neg_counts / (pos_counts + 1e-8)\n",
    "    return pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16633f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'exact_match_accuracy': [],\n",
    "    'hamming_loss': [],\n",
    "    'f1_macro': [],\n",
    "    'f1_micro': [],\n",
    "    'jaccard_index': [],\n",
    "    'element_wise_accuracy': [],\n",
    "    'positive_element_wise_accuracy': [],\n",
    "    'all_outputs': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b572c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(25): # Run 25 rounds of 1 trial each\n",
    "    trials = HPO_client.get_next_trials(max_trials=1)\n",
    "    for trial_i , parameters in trials.items():\n",
    "        # training set up\n",
    "        model = load_model_with_hpo_parameters(parameters)\n",
    "        input_shape = (3, 192, 668) \n",
    "        initial_batch_size = 500 # A reasonable starting point\n",
    "        optimal_batch_size = find_optimal_batch_size(model, input_shape, initial_batch_size, device , memory_usage_fraction=0.9)\n",
    "        train_loader, val_loader, mlb = create_dataloaders(CSV_PATH, IMG_DIR , batch_size=optimal_batch_size, val_split=0.20 , height=192 , width=668)\n",
    "        pos_weights = get_pos_weights(train_loader)\n",
    "        criterion, optimizer, scheduler = setup_training(model, learning_rate=parameters['learning_rate'], pos_weights=pos_weights , total_steps_scheduler=len(train_loader) * epoch , use_focal_loss = True , T_max=60)\n",
    "        # end of training set up\n",
    "        for i in range(0,epoch):\n",
    "            end_idx = (i + 1) * optimal_batch_size\n",
    "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            optimal_threshold = find_optimal_threshold(model, val_loader, device)\n",
    "            metrics = evaluate(model, val_loader, criterion, device , predictions_threshold=optimal_threshold)\n",
    "            raw_data = {\n",
    "                \"score\": metrics['exact_match_accuracy'],\n",
    "            }\n",
    "            #--- Update history ---\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(metrics['loss'])\n",
    "            history['exact_match_accuracy'].append(metrics['exact_match_accuracy'])\n",
    "            history['hamming_loss'].append(metrics['hamming_loss'])\n",
    "            history['f1_macro'].append(metrics['f1_macro'])\n",
    "            history['f1_micro'].append(metrics['f1_micro'])\n",
    "            history['jaccard_index'].append(metrics['jaccard_index'])\n",
    "            history['element_wise_accuracy'].append(metrics['element_wise_accuracy'])\n",
    "            history['positive_element_wise_accuracy'].append(metrics['positive_element_wise_accuracy'])\n",
    "            history['all_outputs'] = metrics['all_outputs']\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Trial {trial_i} - Epoch {epoch} - Train Loss: {train_loss:.4f} - Val Loss: {metrics['loss']:.4f} - Exact Match Accuracy: {metrics['exact_match_accuracy']:.4f} - Hamming Loss: {metrics['hamming_loss']:.4f} - F1 Macro: {metrics['f1_macro']:.4f} - F1 Micro: {metrics['f1_micro']:.4f} - Jaccard Index: {metrics['jaccard_index']:.4f} - Element-wise Accuracy: {metrics['element_wise_accuracy']:.4f} - Positive Element-wise Accuracy: {metrics['positive_element_wise_accuracy']:.4f}\")\n",
    "            if i == epoch - 1:\n",
    "                HPO_client.complete_trial(\n",
    "                    trial_index=trial_i,\n",
    "                    raw_data=raw_data,\n",
    "                    progression=end_idx,  # Use the index of the last example in the batch as the progression value\n",
    "                )\n",
    "                break\n",
    "            HPO_client.attach_data(\n",
    "                trial_index=trial_i,\n",
    "                raw_data=raw_data,\n",
    "                progression=end_idx,\n",
    "            )\n",
    "            if HPO_client.should_stop_trial_early(trial_index=trial_i):\n",
    "                HPO_client.mark_trial_early_stopped(trial_index=trial_i)\n",
    "                break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
