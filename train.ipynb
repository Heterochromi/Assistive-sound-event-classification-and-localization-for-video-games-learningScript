{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029363a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loadset import create_dataloaders\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542e3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ffda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"/home/baraa/Desktop/testroch/DSED_strong_label/dataset/metadata/eval/combined_weak_labels.csv\"\n",
    "IMG_DIR = '/home/baraa/Desktop/testroch/DSED_strong_label/dataset/audio/eval/combined_mel'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9ec612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_cct import MultiLabelCCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a6c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelCCT(\n",
       "  (cct): CCT(\n",
       "    (tokenizer): Tokenizer(\n",
       "      (conv_layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): TransformerClassifier(\n",
       "      (attention_pool): Linear(in_features=192, out_features=1, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (blocks): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (pre_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Attention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "            (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=192, out_features=384, bias=True)\n",
       "          (dropout1): Dropout(p=0.3, inplace=False)\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear2): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (dropout2): Dropout(p=0.3, inplace=False)\n",
       "          (drop_path): DropPath()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Linear(in_features=192, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLabelCCT(\n",
    "        img_size=(192, 668),\n",
    "        embedding_dim=192,\n",
    "        n_input_channels=3,\n",
    "        n_conv_layers=2,\n",
    "        kernel_size=7,\n",
    "        stride=2,\n",
    "        padding=3,\n",
    "        pooling_kernel_size=3,\n",
    "        pooling_stride=2,\n",
    "        pooling_padding=1,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        mlp_ratio=2.0,\n",
    "        dropout_rate=0.3,\n",
    "        attention_dropout=0.3,\n",
    "        # stochastic_depth_rate=0.2,\n",
    "        # num_classes=len(mlb.classes_),\n",
    "        num_classes=15,\n",
    "        positional_embedding='learnable',\n",
    "    )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1eede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,896,587 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"The model has {num_params:,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f4a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dynamic_batching import find_optimal_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fc8802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 23.78 GB\n",
      "Target memory usage: 22.11 GB\n",
      "Batch size 1000 is too large (OOM). Trying smaller.\n",
      "Batch size 500 is too large (OOM). Trying smaller.\n",
      "Batch size 250: Peak memory usage: 13.71 GB\n",
      "Memory usage is low. Trying larger batch size.\n",
      "Batch size 375: Peak memory usage: 20.58 GB\n",
      "Memory usage is low. Trying larger batch size.\n",
      "Batch size 437 is too large (OOM). Trying smaller.\n",
      "Batch size 406: Peak memory usage: 22.28 GB\n",
      "Found optimal batch size 406 within target memory range.\n",
      "Using a dynamic batch size of: 406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine the optimal batch size dynamically\n",
    "# This is a placeholder for the actual input shape from your dataset\n",
    "# You might need to load one sample to get the exact dimensions\n",
    "# Dimensions: (num_channels, height, width)\n",
    "input_shape = (3, 192, 668) \n",
    "initial_batch_size = 500 # A reasonable starting point\n",
    "optimal_batch_size = find_optimal_batch_size(model, input_shape, initial_batch_size, device , memory_usage_fraction=0.93)\n",
    "\n",
    "print(f\"Using a dynamic batch size of: {optimal_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df4036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5266 rows from CSV\n",
      "Found 5266 files in /home/baraa/Desktop/testroch/DSED_strong_label/dataset/audio/eval/combined_mel\n",
      "First row - fname: 500ms_0.png\n",
      "First row - labels: ['Frying']\n",
      "First row - found chunks: 1\n",
      "Total samples created: 5266\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, mlb = create_dataloaders(CSV_PATH, IMG_DIR , batch_size=optimal_batch_size, val_split=0.20 , height=192 , width=668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "930544e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alarm_bell_ringing' 'Blender' 'Blender_nOff' 'Cat' 'Dishes' 'Dog'\n",
      " 'Electric_shaver_toothbrush' 'Frying' 'Frying_nOff' 'Frying_nOn_nOff'\n",
      " 'Running_water' 'Speech' 'Vacuum_cleaner' 'Vacuum_cleaner_nOn'\n",
      " 'Vacuum_cleaner_nOn_nOff']\n"
     ]
    }
   ],
   "source": [
    "print(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73d0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for _, labels in train_loader.dataset:\n",
    "    all_labels.append(labels)\n",
    "all_labels = torch.stack(all_labels)\n",
    "    \n",
    "    # Calculate positive class frequencies\n",
    "pos_counts = all_labels.sum(dim=0)\n",
    "neg_counts = len(all_labels) - pos_counts\n",
    "    \n",
    "    # Use a more conservative weighting scheme\n",
    "# pos_weights = torch.sqrt(neg_counts / (pos_counts + 1e-8))\n",
    "pos_weights = neg_counts / (pos_counts + 1e-8)\n",
    "\n",
    "    # Cap the weights to prevent extreme values\n",
    "pos_weights = torch.clamp(pos_weights, min=1.0, max=10.0)\n",
    "pos_weights = pos_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "525858d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.setup_training import setup_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c71200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 60\n",
    "criterion, optimizer, scheduler = setup_training(model, learning_rate=1e-4, pos_weights=pos_weights , total_steps_scheduler=len(train_loader) * num_epochs , use_focal_loss = True , T_max=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7ab715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.run_epoch_and_eval import train_one_epoch, evaluate, find_optimal_threshold\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03d76b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca72c5",
   "metadata": {},
   "source": [
    "evlaute outputs:\n",
    "    metrics = {\n",
    "        'loss': running_loss / len(val_loader),\n",
    "        'exact_match_accuracy': exact_match_accuracy.item(),\n",
    "        'hamming_loss': hamming_loss.item(),\n",
    "        'f1_macro': f1_macro.item(),\n",
    "        'f1_micro': f1_micro.item(),\n",
    "        'jaccard_index': jaccard.item(),\n",
    "        'element_wise_accuracy': (all_preds == all_labels).float().mean().item()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "676406ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'exact_match_accuracy': [],\n",
    "    'hamming_loss': [],\n",
    "    'f1_macro': [],\n",
    "    'f1_micro': [],\n",
    "    'jaccard_index': [],\n",
    "    'element_wise_accuracy': [],\n",
    "    'positive_element_wise_accuracy': [],\n",
    "    'all_outputs': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6917357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_history(history , epochs_range):\n",
    "    plt.figure(figsize=(18, 14))\n",
    "\n",
    "# Plot Loss\n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs_range, history['val_loss'], label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch\\n\\nLoss measures model error. Lower is better.')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "# Plot Accuracy\n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.plot(epochs_range, history['exact_match_accuracy'], label='Exact Match Accuracy')\n",
    "    plt.plot(epochs_range, history['element_wise_accuracy'], label='Element-wise Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Accuracy Metrics')\n",
    "    plt.xlabel('Epoch\\n\\nAccuracy measures correctness. Higher is better.')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    # Plot F1 Scores\n",
    "    plt.subplot(2, 4, 3)\n",
    "    plt.plot(epochs_range, history['f1_macro'], label='F1 Macro')\n",
    "    plt.plot(epochs_range, history['f1_micro'], label='F1 Micro')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('F1 Scores')\n",
    "    plt.xlabel('Epoch\\n\\nF1 Score is the harmonic mean of precision and recall. Higher is better.')\n",
    "    plt.ylabel('F1 Score')\n",
    "\n",
    "    # Plot Hamming Loss\n",
    "    plt.subplot(2, 4, 4)\n",
    "    plt.plot(epochs_range, history['hamming_loss'], label='Hamming Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Hamming Loss')\n",
    "    plt.xlabel('Epoch\\n\\nHamming Loss is the fraction of wrong labels. Lower is better.')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    # Plot Jaccard Index\n",
    "    plt.subplot(2, 4, 5)\n",
    "    plt.plot(epochs_range, history['jaccard_index'], label='Jaccard Index')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Jaccard Index')\n",
    "    plt.xlabel('Epoch\\n\\nJaccard Index measures similarity. Higher is better.')\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    plt.subplot(2, 4, 6)\n",
    "\n",
    "    plt.hist(np.array(history['all_outputs']).flatten(), bins=50, range=(0, 1))\n",
    "    plt.xlabel(\"Predicted Probability\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Distribution of Model Output Probabilities\")\n",
    "\n",
    "    plt.subplot(2, 4, 7)\n",
    "    plt.plot(epochs_range, history['positive_element_wise_accuracy'], label='Positive Element-wise Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Positive Element-wise Accuracy')\n",
    "    plt.xlabel('Epoch\\n\\nPositive Element-wise Accuracy measures correctness for positive samples. Higher is better.')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7d3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait for improvement before stopping\n",
    "epochs_no_improve = 0\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaa95620",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([406, 15])) must be the same as input size (torch.Size([406, 10]))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     train_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     optimal_threshold = find_optimal_threshold(model, val_loader, device)\n\u001b[32m      4\u001b[39m     metrics = evaluate(model, val_loader, criterion, device , predictions_threshold=optimal_threshold)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/testroch/src/run_epoch_and_eval.py:19\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n\u001b[32m     17\u001b[39m outputs = model(inputs)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m loss.backward()\n\u001b[32m     22\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/testroch/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/testroch/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/testroch/src/setup_training.py:25\u001b[39m, in \u001b[36mSigmoidFocalLoss.forward\u001b[39m\u001b[34m(self, inputs, targets)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m        inputs (torch.Tensor): The raw, un-activated outputs from the model (logits).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33;03m        torch.Tensor: The calculated focal loss.\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     BCE_loss = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     pt = torch.exp(-BCE_loss)  \u001b[38;5;66;03m# Prevents nans when probability is 0\u001b[39;00m\n\u001b[32m     27\u001b[39m     F_loss = (\u001b[32m1\u001b[39m - pt) ** \u001b[38;5;28mself\u001b[39m.gamma * BCE_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/testroch/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3639\u001b[39m, in \u001b[36mbinary_cross_entropy_with_logits\u001b[39m\u001b[34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[39m\n\u001b[32m   3636\u001b[39m     reduction_enum = _Reduction.get_enum(reduction)\n\u001b[32m   3638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target.size() == \u001b[38;5;28minput\u001b[39m.size()):\n\u001b[32m-> \u001b[39m\u001b[32m3639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3640\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3641\u001b[39m     )\n\u001b[32m   3643\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.binary_cross_entropy_with_logits(\n\u001b[32m   3644\u001b[39m     \u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum\n\u001b[32m   3645\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Target size (torch.Size([406, 15])) must be the same as input size (torch.Size([406, 10]))"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    optimal_threshold = find_optimal_threshold(model, val_loader, device)\n",
    "    metrics = evaluate(model, val_loader, criterion, device , predictions_threshold=optimal_threshold)\n",
    "    #--- Update history ---\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(metrics['loss'])\n",
    "    history['exact_match_accuracy'].append(metrics['exact_match_accuracy'])\n",
    "    history['hamming_loss'].append(metrics['hamming_loss'])\n",
    "    history['f1_macro'].append(metrics['f1_macro'])\n",
    "    history['f1_micro'].append(metrics['f1_micro'])\n",
    "    history['jaccard_index'].append(metrics['jaccard_index'])\n",
    "    history['element_wise_accuracy'].append(metrics['element_wise_accuracy'])\n",
    "    history['positive_element_wise_accuracy'].append(metrics['positive_element_wise_accuracy'])\n",
    "    history['all_outputs'] = metrics['all_outputs']\n",
    "    clear_output(wait=True)\n",
    "    plot_history(history, range(start_epoch, start_epoch + len(history['train_loss'])))                # --- Early Stopping Logic ---\n",
    "    val_loss = metrics['loss']\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model state\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss decreased to {val_loss:.4f}. Saving model.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss did not improve. Count: {epochs_no_improve}/{patience}\")\n",
    "        if epochs_no_improve >= patience:\n",
    "         print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "        # Load the best model state before stopping\n",
    "        if best_model_state:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        break\n",
    "\n",
    "# Load the best model state if the loop finished without early stopping\n",
    "if best_model_state:\n",
    "    print(\"Training finished. Loading best model state.\")\n",
    "    model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_checkpoint_path = 'checkpoints/final_model_focal_loss_53ExactMatchAcc.pth'\n",
    "final_checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'mlb': mlb,\n",
    "        }\n",
    "torch.save(final_checkpoint, final_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.setup_training import SigmoidFocalLoss\n",
    "from src.run_epoch_and_eval import evaluate , find_optimal_threshold\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define paths\n",
    "    img_dir = '/home/baraa/Desktop/testroch/DSED_strong_label/mel'\n",
    "    csv_path = '/home/baraa/Desktop/testroch/DSED_strong_label/weak_labels.csv'\n",
    "    # checkpoint_path = '/home/baraa/Desktop/testroch/checkpoints/final_model_focal_loss.pth'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Create DataLoader\n",
    "    test_loader, _, mlb = create_dataloaders(csv_path, img_dir, batch_size=50, val_split=0.0)\n",
    "    \n",
    "    # Load model\n",
    "\n",
    "    # Load checkpoint\n",
    "    # checkpoint = torch.load(checkpoint_path, map_location=device , weights_only=False)\n",
    "    # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Create criterion for evaluation (same as used in training)\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = SigmoidFocalLoss(alpha=None, gamma=2.0, reduction='mean')\n",
    "    optimal_threshold = find_optimal_threshold(model, test_loader, device)\n",
    "\n",
    "    # Evaluate model\n",
    "    metrics = evaluate(model, test_loader, criterion, device , predictions_threshold=optimal_threshold)\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
